# 模型上下文协议 (MCP) 详解

## 概述

模型上下文协议（Model Context Protocol，简称 MCP）是一种开放协议，旨在实现大型语言模型（LLM）应用与外部数据源、工具和服务之间的无缝集成 [[4]]。其核心目标是解决当前 AI 模型因数据孤岛限制而无法充分发挥潜力的难题，为 AI 应用提供了连接万物的接口 [[2]]。MCP 允许应用程序为大型语言模型提供功能和上下文，其主要功能是定义 AI 代理用于完成任务的工具 [[1]]。它定义了应用程序与 LLM 共享上下文的方式，提供了一种将 AI 模型与不同数据源和工具连接起来的标准化方法 [[5]]。

## 核心架构与通信

MCP 假定采用客户端-服务器架构 [[3]]。在此架构中，一个客户端实体（如 AI 代理或辅助程序）向服务器发送请求，而服务器则响应这些请求 [[3]]。MCP 客户端通常在 MCP 主机内运行 [[3]]。MCP 服务器可以在本地运行，但远程 MCP 服务器对于在云规模上共享工具至关重要 [[1]]。

## 技术规范

### 通信协议与消息格式

MCP 的核心是使用 JSON-RPC 2.0 作为其消息格式和传输协议，为客户端和服务器之间的通信提供标准化的方式 [[15]]。所有传输都使用 JSON-RPC 2.0 来交换消息 [[11]]。JSON-RPC 消息必须使用 UTF-8 编码 [[13]]。该协议定义了多种基础消息类型，主要包括请求（Requests）、响应（Responses）和通知（Notifications） [[15]]。

### 传输机制

MCP 协议定义了用于客户端-服务器通信的标准传输机制。主要的两种机制是：
*   **标准输入输出 (STDIO)**：通过宿主应用程序的标准输入和标准输出进行通信 [[16]]。
*   **服务器发送事件 (SSE)**：通过 HTTP 与服务器建立连接，SSE 启动方式下会把 JSON-RPC 消息包装成 SSE 事件 [[16]]。

### 接口定义

MCP Server 通过 Schema（类似 OpenAPI Specification 3 标准）明确定义其提供的工具的能力范围、接口字段（包括类型、校验规则等）以及参数结构 [[7]]。这种强类型定义（通常通过 JSON Schema 实现）支持运行时验证，确保了数据的准确性和一致性 [[14]]。

## 安全机制

MCP 协议本身并未原生内置身份验证、授权或加密，这些安全措施需要由开发人员自行实现或借助相关服务 [[24]]。
*   **认证与授权**：推荐的实践是采用 OAuth 2.0 或 OAuth 2.1 授权框架 [[8]]。MCP 服务器的访问通常需要提供有时效性的 OAuth Token，以实现安全的访问控制 [[21]]。规范也强调了代理置于服务器前、验证令牌和审计访问的重要性 [[28]]。
*   **数据加密**：为了保护数据在传输过程中的安全，避免被窃听或篡改，应使用 TLS/SSL 加密协议 [[20]]。虽然 MCP 不强制要求使用 HTTPS，但最佳实践和新版本规范强烈推荐甚至强制使用 HTTPS，并禁用弱加密套件 [[22]]。